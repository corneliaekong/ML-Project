{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46220f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51d1e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam\n",
       "0     Subject: naturally irresistible your corporate...     1\n",
       "1     Subject: the stock trading gunslinger  fanny i...     1\n",
       "2     Subject: unbelievable new homes made easy  im ...     1\n",
       "3     Subject: 4 color printing special  request add...     1\n",
       "4     Subject: do not have money , get software cds ...     1\n",
       "...                                                 ...   ...\n",
       "5723  Subject: re : research and development charges...     0\n",
       "5724  Subject: re : receipts from visit  jim ,  than...     0\n",
       "5725  Subject: re : enron case study update  wow ! a...     0\n",
       "5726  Subject: re : interest  david ,  please , call...     0\n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0\n",
       "\n",
       "[5728 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_df = pd.read_csv('data/emails.csv')\n",
    "email_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e77ca80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text    0\n",
       "spam    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268c99cb",
   "metadata": {},
   "source": [
    "## Text Preprocessing and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66efcb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to clean the text\n",
    "import string\n",
    "def clean_text(text):\n",
    "    text = ''.join([i for i in text if not i.isdigit()])\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    \n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91372639",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df['cleaned_text'] = email_df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ea5bf90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject  color printing special  request addit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Subject: re : research and development charges...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  research and development charges t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Subject: re : receipts from visit  jim ,  than...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  receipts from visit  jim   thanks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>Subject: re : enron case study update  wow ! a...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  enron case study update  wow  all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>Subject: re : interest  david ,  please , call...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  interest  david   please  call shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>Subject: news : aurora 5 . 2 update  aurora ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject news  aurora    update  aurora version...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam  \\\n",
       "0     Subject: naturally irresistible your corporate...     1   \n",
       "1     Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2     Subject: unbelievable new homes made easy  im ...     1   \n",
       "3     Subject: 4 color printing special  request add...     1   \n",
       "4     Subject: do not have money , get software cds ...     1   \n",
       "...                                                 ...   ...   \n",
       "5723  Subject: re : research and development charges...     0   \n",
       "5724  Subject: re : receipts from visit  jim ,  than...     0   \n",
       "5725  Subject: re : enron case study update  wow ! a...     0   \n",
       "5726  Subject: re : interest  david ,  please , call...     0   \n",
       "5727  Subject: news : aurora 5 . 2 update  aurora ve...     0   \n",
       "\n",
       "                                           cleaned_text  \n",
       "0     subject naturally irresistible your corporate ...  \n",
       "1     subject the stock trading gunslinger  fanny is...  \n",
       "2     subject unbelievable new homes made easy  im w...  \n",
       "3     subject  color printing special  request addit...  \n",
       "4     subject do not have money  get software cds fr...  \n",
       "...                                                 ...  \n",
       "5723  subject re  research and development charges t...  \n",
       "5724  subject re  receipts from visit  jim   thanks ...  \n",
       "5725  subject re  enron case study update  wow  all ...  \n",
       "5726  subject re  interest  david   please  call shi...  \n",
       "5727  subject news  aurora    update  aurora version...  \n",
       "\n",
       "[5728 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16e683e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28f4d30",
   "metadata": {},
   "source": [
    "## Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a44d5e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    without_stopwords = [word for word in tokens if not word in stop_words]\n",
    "    return without_stopwords\n",
    "    \n",
    "email_df['text'] = email_df['text'].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f8376cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Subject, :, naturally, irresistible, corporat...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Subject, :, stock, trading, gunslinger, fanny...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Subject, :, unbelievable, new, homes, made, e...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Subject, :, 4, color, printing, special, requ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject  color printing special  request addit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Subject, :, money, ,, get, software, cds, !, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>[Subject, :, :, research, development, charges...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  research and development charges t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>[Subject, :, :, receipts, visit, jim, ,, thank...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  receipts from visit  jim   thanks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5725</th>\n",
       "      <td>[Subject, :, :, enron, case, study, update, wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  enron case study update  wow  all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>[Subject, :, :, interest, david, ,, please, ,,...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject re  interest  david   please  call shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5727</th>\n",
       "      <td>[Subject, :, news, :, aurora, 5, ., 2, update,...</td>\n",
       "      <td>0</td>\n",
       "      <td>subject news  aurora    update  aurora version...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5728 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  spam  \\\n",
       "0     [Subject, :, naturally, irresistible, corporat...     1   \n",
       "1     [Subject, :, stock, trading, gunslinger, fanny...     1   \n",
       "2     [Subject, :, unbelievable, new, homes, made, e...     1   \n",
       "3     [Subject, :, 4, color, printing, special, requ...     1   \n",
       "4     [Subject, :, money, ,, get, software, cds, !, ...     1   \n",
       "...                                                 ...   ...   \n",
       "5723  [Subject, :, :, research, development, charges...     0   \n",
       "5724  [Subject, :, :, receipts, visit, jim, ,, thank...     0   \n",
       "5725  [Subject, :, :, enron, case, study, update, wo...     0   \n",
       "5726  [Subject, :, :, interest, david, ,, please, ,,...     0   \n",
       "5727  [Subject, :, news, :, aurora, 5, ., 2, update,...     0   \n",
       "\n",
       "                                           cleaned_text  \n",
       "0     subject naturally irresistible your corporate ...  \n",
       "1     subject the stock trading gunslinger  fanny is...  \n",
       "2     subject unbelievable new homes made easy  im w...  \n",
       "3     subject  color printing special  request addit...  \n",
       "4     subject do not have money  get software cds fr...  \n",
       "...                                                 ...  \n",
       "5723  subject re  research and development charges t...  \n",
       "5724  subject re  receipts from visit  jim   thanks ...  \n",
       "5725  subject re  enron case study update  wow  all ...  \n",
       "5726  subject re  interest  david   please  call shi...  \n",
       "5727  subject news  aurora    update  aurora version...  \n",
       "\n",
       "[5728 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "email_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5b0c3c",
   "metadata": {},
   "source": [
    "## Lemmatizing the words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5281cb31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Subject, :, naturally, irresistible, corporat...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Subject, :, stock, trading, gunslinger, fanny...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Subject, :, unbelievable, new, homes, made, e...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Subject, :, 4, color, printing, special, requ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject  color printing special  request addit...</td>\n",
       "      <td>subject  color printing special  request addit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Subject, :, money, ,, get, software, cds, !, ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  \\\n",
       "0  [Subject, :, naturally, irresistible, corporat...     1   \n",
       "1  [Subject, :, stock, trading, gunslinger, fanny...     1   \n",
       "2  [Subject, :, unbelievable, new, homes, made, e...     1   \n",
       "3  [Subject, :, 4, color, printing, special, requ...     1   \n",
       "4  [Subject, :, money, ,, get, software, cds, !, ...     1   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  subject naturally irresistible your corporate ...   \n",
       "1  subject the stock trading gunslinger  fanny is...   \n",
       "2  subject unbelievable new homes made easy  im w...   \n",
       "3  subject  color printing special  request addit...   \n",
       "4  subject do not have money  get software cds fr...   \n",
       "\n",
       "                                          clean_text  \n",
       "0  subject naturally irresistible your corporate ...  \n",
       "1  subject the stock trading gunslinger  fanny is...  \n",
       "2  subject unbelievable new homes made easy  im w...  \n",
       "3  subject  color printing special  request addit...  \n",
       "4  subject do not have money  get software cds fr...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def lemma(text):\n",
    "    lemmatizer = WordNetLemmatizer() # Instantiate lemmatizer\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in text] # Lemmatize\n",
    "    lemmatized_string = \"\".join(lemmatized)\n",
    "    return lemmatized_string\n",
    "\n",
    "email_df['clean_text'] = email_df.cleaned_text.apply(lemma)\n",
    "\n",
    "email_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641bfcf9",
   "metadata": {},
   "source": [
    "## converting textual data to numbers using countvectorizer. Bag of words modelling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8b6a0e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(email_df.clean_text)\n",
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "267605fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5728x33715 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 663785 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = email_df['spam'].values\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed71915",
   "metadata": {},
   "source": [
    "## Model Training using logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b44297",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "041a7f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data to train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=2, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd875948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 1, 1, 0])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c04c317d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deniscornelia123/.pyenv/versions/3.8.12/envs/lewagon/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9a0ff3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_preddict = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "905e2421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of the training data is:  1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(x_train_preddict, y_train)\n",
    "print('the accuracy of the training data is: ', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "772363b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_predict = model.predict(X_test)\n",
    "X_test_accuracy = accuracy_score(X_test_predict, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bb29bbfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9921465968586387"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "751747f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "the email is real\n"
     ]
    }
   ],
   "source": [
    "X_new = X_test[120]\n",
    "\n",
    "prediction = model.predict(X_new)\n",
    "print(prediction)\n",
    "if(prediction[0]==0):\n",
    "    print('the email is real')\n",
    "else:\n",
    "    print('the email is spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dde1a936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb378e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
